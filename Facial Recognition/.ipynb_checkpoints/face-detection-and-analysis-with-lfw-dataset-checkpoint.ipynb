{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # Ignore warnings for cleaner output\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pairs.csv',\n",
       " 'matchpairsDevTest.csv',\n",
       " 'people.csv',\n",
       " 'lfw_readme.csv',\n",
       " 'peopleDevTest.csv',\n",
       " 'mismatchpairsDevTrain.csv',\n",
       " 'lfw-deepfunneled',\n",
       " 'matchpairsDevTrain.csv',\n",
       " 'mismatchpairsDevTest.csv',\n",
       " 'lfw_allnames.csv',\n",
       " '.ipynb_checkpoints',\n",
       " 'peopleDevTrain.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the path to the dataset directory\n",
    "data_dir_path = \"../Facial Recognition/dataset/\"\n",
    "os.makedirs(data_dir_path, exist_ok=True) # Create the directory if it doesn't exist\n",
    "all_files = os.listdir(data_dir_path)\n",
    "all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the images directory\n",
    "images_data_dir = os.path.join(data_dir_path, 'lfw-deepfunneled', 'lfw-deepfunneled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of persons (directories) in the images directory\n",
    "persons = os.listdir(images_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5749"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(persons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hedayat_Amin_Arsala'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a random person from the dataset\n",
    "random_person = random.choice(persons)\n",
    "random_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hedayat_Amin_Arsala_0001.jpg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select some images from the random person's directory\n",
    "image_select = os.listdir(os.path.join(images_data_dir, random_person))\n",
    "image_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = image_select[:5]\n",
    "\n",
    "# Extract properties of selected images (name, size, format)\n",
    "image_properties = []\n",
    "for image_name in sample:\n",
    "    image_path = os.path.join(images_data_dir, random_person, image_name)\n",
    "    img = Image.open(image_path)\n",
    "    image_properties.append((image_name, img.size, img.format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hedayat_Amin_Arsala_0001.jpg', (250, 250), 'JPEG')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose 5 random persons from the dataset\n",
    "random_person = random.sample(persons, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mark_Hurlbert',\n",
       " 'John_Cusack',\n",
       " 'Wendy_Kennedy',\n",
       " 'Camilla_Parker_Bowles',\n",
       " 'Hank_Aaron']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Facial Recognition/dataset/lfw-deepfunneled/lfw-deepfunneled/Mark_Hurlbert/Mark_Hurlbert_0003.jpg',\n",
       " '../Facial Recognition/dataset/lfw-deepfunneled/lfw-deepfunneled/John_Cusack/John_Cusack_0002.jpg',\n",
       " '../Facial Recognition/dataset/lfw-deepfunneled/lfw-deepfunneled/Wendy_Kennedy/Wendy_Kennedy_0001.jpg',\n",
       " '../Facial Recognition/dataset/lfw-deepfunneled/lfw-deepfunneled/Camilla_Parker_Bowles/Camilla_Parker_Bowles_0002.jpg',\n",
       " '../Facial Recognition/dataset/lfw-deepfunneled/lfw-deepfunneled/Hank_Aaron/Hank_Aaron_0001.jpg']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select one random image from each of the 5 random persons\n",
    "select_images = []\n",
    "for person in random_person:\n",
    "    person_dir = os.path.join(images_data_dir, person)\n",
    "    person_file = os.listdir(person_dir)\n",
    "    select_person_image_file = random.choice(person_file)\n",
    "    select_images.append(os.path.join(person_dir, select_person_image_file))\n",
    "    \n",
    "select_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Akhmed_Zakayev'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = '../Facial Recognition/dataset/lfw-deepfunneled/lfw-deepfunneled/Akhmed_Zakayev/Akhmed_Zakayev_0003.jpg'\n",
    "a.split('/')[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-27T11:14:10.624381Z",
     "iopub.status.busy": "2024-04-27T11:14:10.623752Z",
     "iopub.status.idle": "2024-04-27T11:14:11.225942Z",
     "shell.execute_reply": "2024-04-27T11:14:11.22496Z",
     "shell.execute_reply.started": "2024-04-27T11:14:10.624348Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display the selected images\n",
    "fig, axs = plt.subplots(1, 5, figsize = (15, 3))\n",
    "for i, image_path in enumerate(select_images):\n",
    "    img = mpimg.imread(image_path)\n",
    "    axs[i].imshow(img)\n",
    "    axs[i].set_title(select_images[i].split('/')[-2]) # Extract person's name from the path\n",
    "    axs[i].axis('off')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-27T11:14:11.227381Z",
     "iopub.status.busy": "2024-04-27T11:14:11.227032Z",
     "iopub.status.idle": "2024-04-27T11:14:11.373804Z",
     "shell.execute_reply": "2024-04-27T11:14:11.372867Z",
     "shell.execute_reply.started": "2024-04-27T11:14:11.227348Z"
    }
   },
   "outputs": [],
   "source": [
    "random_person = np.random.choice(persons, 15, replace = False) # replace = False means no duplicate.\n",
    "select_images = []\n",
    "for person in random_person:\n",
    "    person_dir = os.path.join(images_data_dir, person)\n",
    "    person_file = os.listdir(person_dir)\n",
    "    select_person_image_file = random.choice(person_file)\n",
    "    select_images.append(os.path.join(person_dir, select_person_image_file))\n",
    "    \n",
    "select_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-27T11:14:11.375563Z",
     "iopub.status.busy": "2024-04-27T11:14:11.375202Z",
     "iopub.status.idle": "2024-04-27T11:14:13.096741Z",
     "shell.execute_reply": "2024-04-27T11:14:13.095889Z",
     "shell.execute_reply.started": "2024-04-27T11:14:11.375526Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 5, figsize = (15, 9))\n",
    "for i, image_path in enumerate(select_images):\n",
    "    img = mpimg.imread(image_path)\n",
    "    axs[i // 5, i % 5].imshow(img)\n",
    "    axs[i // 5, i % 5].set_title(select_images[i].split('/')[-2])\n",
    "    axs[i // 5, i % 5].axis('off')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-27T11:14:13.099237Z",
     "iopub.status.busy": "2024-04-27T11:14:13.098333Z",
     "iopub.status.idle": "2024-04-27T11:14:14.347976Z",
     "shell.execute_reply": "2024-04-27T11:14:14.346868Z",
     "shell.execute_reply.started": "2024-04-27T11:14:13.099208Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read metadata about the dataset\n",
    "allNames = pd.read_csv(\"/kaggle/input/lfw-dataset/lfw_allnames.csv\")\n",
    "\n",
    "# Plot a histogram of the number of images per person\n",
    "plt.figure(figsize = (10, 6))\n",
    "plt.hist(allNames['images'], bins = 50, color = \"blue\", edgecolor=\"black\")\n",
    "plt.title(\"Image Count\")\n",
    "plt.xlabel(\"NUmber of Images\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-27T11:14:14.349628Z",
     "iopub.status.busy": "2024-04-27T11:14:14.349282Z",
     "iopub.status.idle": "2024-04-27T11:14:14.36276Z",
     "shell.execute_reply": "2024-04-27T11:14:14.3618Z",
     "shell.execute_reply.started": "2024-04-27T11:14:14.349596Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display summary statistics of the number of images per person\n",
    "allNames[\"images\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-27T11:14:14.364578Z",
     "iopub.status.busy": "2024-04-27T11:14:14.364183Z",
     "iopub.status.idle": "2024-04-27T11:14:15.201041Z",
     "shell.execute_reply": "2024-04-27T11:14:15.200042Z",
     "shell.execute_reply.started": "2024-04-27T11:14:14.364545Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load an example image and perform face detection\n",
    "import cv2\n",
    "image = cv2.imread('/kaggle/input/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled/Abdul_Rahman/Abdul_Rahman_0001.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Use Haar Cascade classifier for face detection\n",
    "face_detect = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "faces = face_detect.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "# Draw bounding boxes around detected faces\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(image, (x, y), (x+w ,y+h), (255, 0, 0), 2) # thickness of rectangle = 2.\n",
    "    \n",
    "# Display the image with bounding boxes    \n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-27T11:14:15.202504Z",
     "iopub.status.busy": "2024-04-27T11:14:15.202221Z",
     "iopub.status.idle": "2024-04-27T11:14:17.390155Z",
     "shell.execute_reply": "2024-04-27T11:14:17.389249Z",
     "shell.execute_reply.started": "2024-04-27T11:14:15.202479Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting images with bounding boxes\n",
    "fig, axs = plt.subplots(3, 5, figsize=(15, 9))\n",
    "for i, image_path in enumerate(select_images):\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "     # Detect faces in the image\n",
    "    face_detect = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    faces = face_detect.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    \n",
    "    # Draw bounding boxes around detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    \n",
    "    axs[i // 5, i % 5].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    axs[i // 5, i % 5].set_title(image_path.split('/')[-2]) # Extract person's name from the path\n",
    "    axs[i // 5, i % 5].axis('off')\n",
    "    axs[i // 5, i % 5].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 26922,
     "sourceId": 34595,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
